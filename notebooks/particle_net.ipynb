{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Jet Energy Regression with ParticleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Activation, Add, BatchNormalization, Conv2D, Dense, Dropout, Layer, Multiply, Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data location and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "block:user_specified_info"
    ]
   },
   "outputs": [],
   "source": [
    "data_dir = '/eos/cms/store/group/phys_jetmet/dholmber/jec-dnn/preprocessed/dev'\n",
    "\n",
    "jet_numerical = ['log_pt', 'eta', 'mass', 'phi', 'area', 'qgl_axis2', 'qgl_ptD', 'qgl_mult']\n",
    "jet_categorical = ['puId', 'partonFlavour']\n",
    "\n",
    "mandatory_pf = ['rel_pt', 'rel_eta', 'rel_phi'] # order must be as is\n",
    "pf_numerical = mandatory_pf + ['d0', 'dz', 'd0Err', 'dzErr', 'trkChi2', 'vtxChi2', 'puppiWeight', 'puppiWeightNoLep']\n",
    "pf_categorical = ['charge', 'lostInnerHits', 'pdgId', 'pvAssocQuality', 'trkQuality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "pipeline-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 256\n",
    "\n",
    "loss = 'mean_absolute_error'\n",
    "optimizer = 'adam'\n",
    "lr = 1.0e-3\n",
    "shortcut = False\n",
    "dropout = 0\n",
    "activation = 'relu'\n",
    "initializer = 'he_normal'\n",
    "pooling = 'average' # average or max\n",
    "batch_norm = False\n",
    "\n",
    "K = 16\n",
    "\n",
    "num_conv_layers = 3\n",
    "num_channels = 3\n",
    "first_channel = 64\n",
    "channel_scale = 2 \n",
    "num_dense_layers = 3\n",
    "first_layer = 256\n",
    "unit_scale = 0.5\n",
    "\n",
    "shuffle_buffer = 64\n",
    "\n",
    "train_size = 0.6\n",
    "test_size = 0.2\n",
    "val_size = 0.2\n",
    "\n",
    "num_points = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "block:get_metadata",
     "prev:user_specified_info"
    ]
   },
   "outputs": [],
   "source": [
    "record_files = glob.glob(os.path.join(data_dir, '*.tfrecords'))\n",
    "\n",
    "num_files = len(record_files)\n",
    "train_split = int(train_size * num_files)\n",
    "test_split = int(test_size * num_files) + train_split\n",
    "\n",
    "train_files = record_files[:train_split]\n",
    "test_files = record_files[train_split:test_split]\n",
    "val_files = record_files[test_split:]\n",
    "\n",
    "jet_fields = jet_numerical + jet_categorical\n",
    "pf_fields = pf_numerical + pf_categorical\n",
    "\n",
    "jet_keys = [f'jet_{field}' for field in jet_fields]\n",
    "pf_keys = [f'pf_{field}' for field in pf_fields]\n",
    "\n",
    "num_jet = len(jet_keys)\n",
    "num_pf = len(pf_keys)\n",
    "\n",
    "def calculate_factors(num_layers, scale):\n",
    "    factors = [1]\n",
    "    for i in range(num_layers - 1):\n",
    "        factors.append(scale * factors[i])\n",
    "    return factors\n",
    "\n",
    "channels = [num_channels * [int(factor * first_channel)] for factor in calculate_factors(num_conv_layers, channel_scale)]\n",
    "units = [int(factor * first_layer) for factor in calculate_factors(num_dense_layers, unit_scale)]\n",
    "\n",
    "with open(os.path.join(data_dir, 'metadata.pkl'), 'rb') as f:\n",
    "    all_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "functions"
    ]
   },
   "outputs": [],
   "source": [
    "def parse_record(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, features=all_features)\n",
    "\n",
    "def select_features(batch):\n",
    "    jet_data = tf.stack([batch[key] for key in jet_keys], axis=1)\n",
    "    pf_data = tf.stack([batch[key].values for key in pf_keys], axis=1)\n",
    "    pf_data = tf.RaggedTensor.from_row_lengths(pf_data, row_lengths=batch['row_lengths']).to_tensor(shape=(None, num_points, num_pf))\n",
    "    \n",
    "    mask = tf.cast(tf.math.not_equal(pf_data[:,:,0:1], 0), dtype=tf.float32) # 1 if valid\n",
    "    coord_shift = tf.multiply(1e6, tf.cast(tf.math.equal(mask, 0), dtype=tf.float32))\n",
    "    points = tf.concat([pf_data[:,:,1:2], pf_data[:,:,2:3]], axis=2)\n",
    "    \n",
    "    inputs = (pf_data, jet_data, points, coord_shift, mask)\n",
    "    return inputs, batch['target']\n",
    "\n",
    "def create_dataset(paths):\n",
    "    ds = tf.data.TFRecordDataset(filenames=[record_files], num_parallel_reads=tf.data.experimental.AUTOTUNE)\n",
    "    ds = ds.map(parse_record, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.map(select_features, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "block:create_datasets",
     "prev:get_metadata"
    ]
   },
   "outputs": [],
   "source": [
    "train_ds = create_dataset(train_files).shuffle(shuffle_buffer)\n",
    "val_ds = create_dataset(val_files)\n",
    "test_ds = create_dataset(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "functions"
    ]
   },
   "outputs": [],
   "source": [
    "class Mean(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.math.reduce_mean(inputs, axis=self.axis)\n",
    "\n",
    "\n",
    "class Max(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.math.reduce_max(inputs, axis=self.axis)\n",
    "\n",
    "\n",
    "class Expand(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.expand_dims(inputs, axis=self.axis)\n",
    "\n",
    "\n",
    "class Squeeze(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.squeeze(inputs, axis=self.axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "functions"
    ]
   },
   "outputs": [],
   "source": [
    "def get_particle_net():\n",
    "    \"\"\"\n",
    "    ParticleNet: Jet Tagging via Particle Clouds\n",
    "    arxiv.org/abs/1902.08570\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shapes : dict\n",
    "        The shapes of each input (`points`, `features`, `mask`).\n",
    "    \"\"\"\n",
    "\n",
    "    features = Input(name='features', shape=(num_points, num_pf))\n",
    "    globals = Input(name='globals', shape=(num_jet,))\n",
    "    points = Input(name='points', shape=(num_points, 2))\n",
    "    coord_shift = Input(name='coord_shift', shape=(num_points, 1))\n",
    "    mask = Input(name='mask', shape=(num_points, 1))\n",
    "\n",
    "    outputs = particle_net_base(points, features, mask, coord_shift, globals)\n",
    "\n",
    "    model = Model(inputs=[features, globals, points, coord_shift, mask], outputs=outputs)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def particle_net_base(points, features, mask, coord_shift, globals):\n",
    "    \"\"\"\n",
    "    points : (N, P, C_coord)\n",
    "    features:  (N, P, C_features), optional\n",
    "    mask: (N, P, 1), optional\n",
    "    \"\"\"\n",
    "\n",
    "    fts = features\n",
    "    for layer_idx, sub_channels in enumerate(channels, start=1):\n",
    "        pts = Add(name=f'add_{layer_idx}')([coord_shift, points]) if layer_idx == 1 else Add(name=f'add_{layer_idx}')([coord_shift, fts])\n",
    "        fts = edge_conv(\n",
    "            pts, fts, num_points, sub_channels, name=f'edge_conv_{layer_idx}'\n",
    "        )\n",
    "\n",
    "    fts = Multiply()([fts, mask])\n",
    "\n",
    "    pool = Mean(axis=1)(fts) # (N, C)\n",
    "\n",
    "    x = Concatenate(name='head')([pool, globals])\n",
    "\n",
    "    for layer_idx, n in enumerate(units):\n",
    "        x = Dense(n)(x)\n",
    "        x = Activation(activation)(x)\n",
    "        if dropout:\n",
    "            x = Dropout(dropout)(x)\n",
    "    out = Dense(1, name='out')(x)\n",
    "    return out # (N, num_classes)\n",
    "\n",
    "\n",
    "def edge_conv(points, features, num_points, sub_channels, name):\n",
    "    \"\"\"EdgeConv\n",
    "    Args:\n",
    "        K: int, number of neighbors\n",
    "        in_channels: # of input channels\n",
    "        channels: tuple of output channels\n",
    "        pooling: pooling method ('max' or 'average')\n",
    "    Inputs:\n",
    "        points: (N, P, C_p)\n",
    "        features: (N, P, C_0)\n",
    "    Returns:\n",
    "        transformed points: (N, P, C_out), C_out = channels[-1]\n",
    "    \"\"\"\n",
    "\n",
    "    fts = features\n",
    "    knn_fts = KNearestNeighbors(num_points, K, name=f'{name}_knn')([points, fts])\n",
    "\n",
    "    x = knn_fts\n",
    "    for idx, channel in enumerate(sub_channels, start=1):\n",
    "        x = Conv2D(\n",
    "            channel, kernel_size=(1, 1), strides=1, data_format='channels_last',\n",
    "            use_bias=False if batch_norm else True, kernel_initializer=initializer, name=f'{name}_conv_{idx}'\n",
    "        )(x)\n",
    "        if batch_norm:\n",
    "            x = BatchNormalization(name=f'{name}_batchnorm_{idx}')(x)\n",
    "        if activation:\n",
    "            x = Activation(activation, name=f'{name}_activation_{idx}')(x)\n",
    "\n",
    "    if pooling == 'max':\n",
    "        fts = Max(axis=2, name=f'{name}_max')(x) # (N, P, C')\n",
    "    else:\n",
    "        fts = Mean(axis=2, name=f'{name}_mean')(x) # (N, P, C')\n",
    "\n",
    "    if shortcut:\n",
    "        sc = Expand(axis=2, name=f'{name}_shortcut_expand')(features)\n",
    "        sc = Conv2D(\n",
    "            sub_channels[-1], kernel_size=(1, 1), strides=1, data_format='channels_last',\n",
    "            use_bias=False if batch_norm else True, kernel_initializer=initializer, name=f'{name}_shortcut_conv'\n",
    "        )(sc)\n",
    "        if batch_norm:\n",
    "            sc = BatchNormalization(name=f'{name}_shortcut_batchnorm')(sc)\n",
    "        sc = Squeeze(axis=2, name=f'{name}_shortcut_squeeze')(sc)\n",
    "\n",
    "        x = Add(name=f'{name}_add')([sc, fts])\n",
    "    else:\n",
    "        x = fts\n",
    "\n",
    "    return Activation(activation, name=f'{name}_activation')(x) # (N, P, C')\n",
    "\n",
    "\n",
    "class KNearestNeighbors(Layer):\n",
    "    def __init__(self, num_points, k, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_points = num_points\n",
    "        self.k = k\n",
    "\n",
    "    def call(self, inputs):\n",
    "        points, features = inputs\n",
    "        # distance\n",
    "        D = batch_distance_matrix_general(points, points) # (N, P, P)\n",
    "        _, top_k_indices = tf.math.top_k(-D, k=self.k + 1) # (N, P, K+1)\n",
    "        top_k_indices = top_k_indices[:, :, 1:] # (N, P, K)\n",
    "\n",
    "        queries_shape = tf.shape(features)\n",
    "        batch_size = queries_shape[0]\n",
    "        batch_indices = tf.tile(tf.reshape(tf.range(batch_size), (-1, 1, 1, 1)), (1, self.num_points, self.k, 1))\n",
    "        indices = tf.concat([batch_indices, tf.expand_dims(top_k_indices, axis=3)], axis=3) # (N, P, K, 2)\n",
    "        \n",
    "        knn_fts =  tf.gather_nd(features, indices) # (N, P, K, C)\n",
    "        knn_fts_center = tf.tile(tf.expand_dims(features, axis=2), (1, 1, self.k, 1)) # (N, P, K, C)\n",
    "\n",
    "        return tf.concat([knn_fts_center, tf.subtract(knn_fts, knn_fts_center)], axis=-1) # (N, P, K, 2*C)\n",
    "\n",
    "\n",
    "# A shape is (N, P_A, C), B shape is (N, P_B, C)\n",
    "# D shape is (N, P_A, P_B)\n",
    "def batch_distance_matrix_general(A, B):\n",
    "    r_A = tf.math.reduce_sum(A * A, axis=2, keepdims=True)\n",
    "    r_B = tf.math.reduce_sum(B * B, axis=2, keepdims=True)\n",
    "    m = tf.linalg.matmul(A, tf.transpose(B, perm=(0, 2, 1)))\n",
    "    D = r_A - 2 * m + tf.transpose(r_B, perm=(0, 2, 1))\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "block:compile_model",
     "prev:create_datasets"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "coord_shift (InputLayer)        [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "points (InputLayer)             [(None, 100, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 100, 2)       0           coord_shift[0][0]                \n",
      "                                                                 points[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           [(None, 100, 16)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_knn (KNearestNeighb (None, 100, 16, 32)  0           add_1[0][0]                      \n",
      "                                                                 features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_conv_1 (Conv2D)     (None, 100, 16, 64)  2112        edge_conv_1_knn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_activation_1 (Activ (None, 100, 16, 64)  0           edge_conv_1_conv_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_conv_2 (Conv2D)     (None, 100, 16, 64)  4160        edge_conv_1_activation_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_activation_2 (Activ (None, 100, 16, 64)  0           edge_conv_1_conv_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_conv_3 (Conv2D)     (None, 100, 16, 64)  4160        edge_conv_1_activation_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_activation_3 (Activ (None, 100, 16, 64)  0           edge_conv_1_conv_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_mean (Mean)         (None, 100, 64)      0           edge_conv_1_activation_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_activation (Activat (None, 100, 64)      0           edge_conv_1_mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 100, 64)      0           coord_shift[0][0]                \n",
      "                                                                 edge_conv_1_activation[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_knn (KNearestNeighb (None, 100, 16, 128) 0           add_2[0][0]                      \n",
      "                                                                 edge_conv_1_activation[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_conv_1 (Conv2D)     (None, 100, 16, 128) 16512       edge_conv_2_knn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_activation_1 (Activ (None, 100, 16, 128) 0           edge_conv_2_conv_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_conv_2 (Conv2D)     (None, 100, 16, 128) 16512       edge_conv_2_activation_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_activation_2 (Activ (None, 100, 16, 128) 0           edge_conv_2_conv_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_conv_3 (Conv2D)     (None, 100, 16, 128) 16512       edge_conv_2_activation_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_activation_3 (Activ (None, 100, 16, 128) 0           edge_conv_2_conv_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_mean (Mean)         (None, 100, 128)     0           edge_conv_2_activation_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_activation (Activat (None, 100, 128)     0           edge_conv_2_mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 100, 128)     0           coord_shift[0][0]                \n",
      "                                                                 edge_conv_2_activation[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_knn (KNearestNeighb (None, 100, 16, 256) 0           add_3[0][0]                      \n",
      "                                                                 edge_conv_2_activation[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_conv_1 (Conv2D)     (None, 100, 16, 256) 65792       edge_conv_3_knn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_activation_1 (Activ (None, 100, 16, 256) 0           edge_conv_3_conv_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_conv_2 (Conv2D)     (None, 100, 16, 256) 65792       edge_conv_3_activation_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_activation_2 (Activ (None, 100, 16, 256) 0           edge_conv_3_conv_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_conv_3 (Conv2D)     (None, 100, 16, 256) 65792       edge_conv_3_activation_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_activation_3 (Activ (None, 100, 16, 256) 0           edge_conv_3_conv_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_mean (Mean)         (None, 100, 256)     0           edge_conv_3_activation_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_activation (Activat (None, 100, 256)     0           edge_conv_3_mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "mask (InputLayer)               [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 100, 256)     0           edge_conv_3_activation[0][0]     \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "mean (Mean)                     (None, 256)          0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "globals (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "head (Concatenate)              (None, 266)          0           mean[0][0]                       \n",
      "                                                                 globals[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          68352       head[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8256        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out (Dense)                     (None, 1)            65          activation_2[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 366,913\n",
      "Trainable params: 366,913\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=0.001>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn = get_particle_net()\n",
    "dnn.compile(optimizer=optimizer, loss=loss)\n",
    "dnn.optimizer.lr.assign(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "block:train_model",
     "prev:compile_model",
     "limit:nvidia.com/gpu:1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 6s 2s/step - loss: 6.7503 - val_loss: 3.9049\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 2s 494ms/step - loss: 2.6290 - val_loss: 1.5741\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 2s 502ms/step - loss: 1.1686 - val_loss: 0.6607\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 2s 488ms/step - loss: 0.6796 - val_loss: 0.3746\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 2s 499ms/step - loss: 0.4166 - val_loss: 0.2509\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 2s 500ms/step - loss: 0.3541 - val_loss: 0.2777\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 2s 497ms/step - loss: 0.2674 - val_loss: 0.2650\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 2s 510ms/step - loss: 0.2111 - val_loss: 0.1595\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 2s 500ms/step - loss: 0.1518 - val_loss: 0.1880\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 2s 502ms/step - loss: 0.1681 - val_loss: 0.1318\n"
     ]
    }
   ],
   "source": [
    "fit = dnn.fit(train_ds, validation_data=val_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "block:model_evalutaion",
     "prev:train_model"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4/Unknown - 1s 164ms/step - loss: 0.1318"
     ]
    }
   ],
   "source": [
    "result = dnn.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "pipeline-metrics",
     "prev:train_model"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13182656280696392\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "gitlab-registry.cern.ch/ai-ml/kubeflow_images/tensorflow-notebook-gpu-2.1.0:v0.6.1-30",
   "experiment": {
    "id": "new",
    "name": "jec-dnn"
   },
   "experiment_name": "jec-dnn",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "random",
     "algorithmSettings": [
      {
       "name": "random_state",
       "value": "10"
      },
      {
       "name": "acq_optimizer",
       "value": "auto"
      },
      {
       "name": "acq_func",
       "value": "gp_hedge"
      },
      {
       "name": "n_initial_points",
       "value": "10"
      },
      {
       "name": "base_estimator",
       "value": "GP"
      }
     ]
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "additionalMetricNames": [],
     "objectiveMetricName": "result",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": true,
   "pipeline_description": "Jet energy regression using particle net",
   "pipeline_name": "particle-net",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volume_access_mode": "rwm",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
