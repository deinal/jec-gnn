{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.nanoevents import NanoEventsFactory, PFNanoAODSchema\n",
    "PFNanoAODSchema.warn_missing_crossrefs = False\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_dir = '/eos/cms/store/group/phys_jetmet/dholmber/jec-dnn/raw'\n",
    "# preprocessed_dir = '/eos/cms/store/group/phys_jetmet/dholmber/jec-dnn/preprocessed'\n",
    "raw_dir = '/ssd-home/hdaniel/jec-dnn/data'\n",
    "preprocessed_dir = '/ssd-home/hdaniel/lab/jec-dnn/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'test'\n",
    "\n",
    "in_dir = os.path.join(raw_dir, dataset)\n",
    "out_dir = os.path.join(preprocessed_dir, dataset)\n",
    "\n",
    "root_files = glob.glob(os.path.join(in_dir, '*.root'))\n",
    "num_files = len(root_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(out_dir)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_features = ['pt', 'eta', 'mass', 'phi', 'area', 'qgl_axis2', 'qgl_ptD', 'qgl_mult', 'partonFlavour']\n",
    "pf_features = ['pt', 'eta', 'phi', 'd0', 'dz', 'd0Err', 'dzErr', 'trkChi2', 'vtxChi2', 'puppiWeight', 'puppiWeightNoLep', 'charge', 'lostInnerHits', 'pdgId', 'pvAssocQuality', 'trkQuality']\n",
    "\n",
    "categorical_map = {\n",
    "    'jet': {\n",
    "        'partonFlavour': [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 21]\n",
    "    },\n",
    "    'pf': {\n",
    "        'charge': [-1, 0, 1],\n",
    "        'lostInnerHits': [-1, 0, 1, 2],\n",
    "        'pdgId': [-211, -13, -11, 1, 2, 11, 13, 22, 130, 211],\n",
    "        'pvAssocQuality': [0, 1, 4, 5, 6, 7],\n",
    "        'trkQuality': [0, 1, 5]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nanoaod(path):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', message='found duplicate branch')\n",
    "        events = NanoEventsFactory.from_root(path, schemaclass=PFNanoAODSchema).events()\n",
    "\n",
    "    jets = events.Jet[(ak.count(events.Jet.matched_gen.pt, axis=1) >= 2)]\n",
    "\n",
    "    sorted_jets = jets[ak.argsort(jets.matched_gen.pt, ascending=False, axis=1)]\n",
    "\n",
    "    leading_jets = ak.concatenate((sorted_jets[:,0], sorted_jets[:,1]), axis=0)\n",
    "\n",
    "    selected_jets = leading_jets[(leading_jets.matched_gen.pt > 15) & (abs(leading_jets.matched_gen.eta) < 5)]\n",
    "\n",
    "    valid_jets = selected_jets[~ak.is_none(selected_jets.matched_gen.pt)]\n",
    "\n",
    "    for field in ['dz', 'dzErr', 'd0', 'd0Err']:\n",
    "        valid_jets = valid_jets[ak.all(valid_jets.constituents.pf[field] != np.inf, axis=1)]\n",
    "\n",
    "    return valid_jets, valid_jets.constituents.pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(array, categories):\n",
    "    cardinality = len(categories)\n",
    "    category_map = dict(zip(categories, range(cardinality)))\n",
    "    for i, val in enumerate(array):\n",
    "        array[i] = category_map[val]\n",
    "    return np.eye(cardinality)[array]\n",
    "\n",
    "def preprocess(jet, pf, jet_features, pf_features):\n",
    "    # Preprocess numerical features\n",
    "    jet['target'] = jet.matched_gen.pt / jet.pt\n",
    "    jet_features.append('target')\n",
    "    jet['log_pt'] = np.log(jet.pt)\n",
    "    jet_features.append('log_pt')\n",
    "    pf['rel_eta'] = (pf.eta - jet.eta) * np.sign(jet.eta)\n",
    "    pf_features.append('rel_eta')\n",
    "    pf['rel_pt'] = pf.pt / jet.pt\n",
    "    pf_features.append('rel_pt')\n",
    "    pf['rel_phi'] = (pf.phi - jet.phi + np.pi) % (2 * np.pi) - np.pi\n",
    "    pf_features.append('rel_phi')\n",
    "    \n",
    "    # One hot encode categorical features\n",
    "    for key, categories in categorical_map['jet'].items():\n",
    "        encoded_matrix = one_hot_encode(np.array(jet[key]), categories)\n",
    "        for i in range(len(categories)):\n",
    "            field = f'{key}_{i}'\n",
    "            jet[field] = encoded_matrix[:,i]\n",
    "            jet_features.append(field)\n",
    "    \n",
    "    counts = ak.num(pf)\n",
    "    flat_pf = ak.flatten(pf)\n",
    "    for key, categories in categorical_map['pf'].items():\n",
    "        encoded_matrix = one_hot_encode(np.array(flat_pf[key]), categories)\n",
    "        for i in range(len(categories)):\n",
    "            field = f'{key}_{i}'\n",
    "            flat_pf[field] = encoded_matrix[:,i]\n",
    "            pf_features.append(field)\n",
    "    pf = ak.unflatten(flat_pf, counts)\n",
    "    \n",
    "    # Select gen level features for result plots\n",
    "    jet['gen_pt'] = jet.matched_gen.pt\n",
    "    jet_features.append('gen_pt')\n",
    "    jet['gen_eta'] = jet.matched_gen.eta\n",
    "    jet_features.append('gen_eta')\n",
    "    jet['gen_partonFlavour'] = jet.matched_gen.partonFlavour\n",
    "    jet_features.append('gen_partonFlavour')\n",
    "    jet['gen_hadronFlavour'] = jet.matched_gen.hadronFlavour\n",
    "    jet_features.append('gen_hadronFlavour')\n",
    "    \n",
    "    return jet[jet_features], pf[pf_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(root_file, parquet_dir):\n",
    "    print(parquet_dir)\n",
    "    \n",
    "    # Create a Features message using tf.train.Example.\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_record(root_file, record_file):    \n",
    "    jet, pf = read_nanoaod(root_file)\n",
    "    jet, pf = preprocess(jet, pf, jet_features.copy(), pf_features.copy())\n",
    "    \n",
    "    row_lengths = ak.num(pf)\n",
    "    targets = jet.target\n",
    "    \n",
    "    with tf.io.TFRecordWriter(record_file) as writer:\n",
    "        for i in tqdm(range(len(jet))):\n",
    "            example = serialize_example(jet[i], pf[i], targets[i], row_lengths[i])\n",
    "            writer.write(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet_dirs = ['/'.join((path, str(index))) for index, path in enumerate(itertools.repeat(out_dir, num_files), start=1)]\n",
    "# for i in range(len(root_files)):\n",
    "#     create_dataset(root_files[i], parquet_dirs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProcessPoolExecutor(max_workers=None) as executor:\n",
    "    parquet_dirs = ['/'.join((path, str(index))) for index, path in enumerate(itertools.repeat(out_dir, num_files), start=1)]\n",
    "    results = executor.map(create_dataset, root_files, parquet_dirs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "gitlab-registry.cern.ch/ai-ml/kubeflow_images/tensorflow-notebook-gpu-2.1.0:v0.6.1-30",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volume_access_mode": "rwm",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
