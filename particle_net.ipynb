{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 11:27:06.343818: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/nvidia-driver/lib64\n",
      "2021-07-21 11:27:06.343874: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/eos/cms/store/group/phys_jetmet/dholmber/jec-dnn'\n",
    "parquet_dir = os.path.join(data_dir, 'preprocessed/dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 256\n",
    "loss = 'mean_absolute_error'\n",
    "optimizer = 'adam'\n",
    "lr = 1.e-3\n",
    "\n",
    "activation = 'relu'\n",
    "initializer = 'he_normal'\n",
    "pooling = 'average' # average or max\n",
    "batch_norm = False\n",
    "shortcut = False\n",
    "dropout = 0\n",
    "K = 16\n",
    "channels = [\n",
    "  [64, 64, 64],\n",
    "  [128, 128, 128],\n",
    "  [256, 256, 256]\n",
    "]\n",
    "units = [128, 128]\n",
    "\n",
    "train_size = 0.6\n",
    "test_size = 0.2\n",
    "val_size = 0.2\n",
    "\n",
    "num_points = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_numerical = ['pt_log', 'eta', 'mass', 'phi', 'area', 'qgl_axis2', 'qgl_ptD', 'qgl_mult']\n",
    "jet_categorical = ['puId', 'partonFlavour']\n",
    "\n",
    "pf_numerical = ['rel_pt', 'rel_eta', 'rel_phi', 'd0', 'dz', 'd0Err', 'dzErr', 'trkChi2', 'vtxChi2', 'puppiWeight', 'puppiWeightNoLep']\n",
    "pf_categorical = ['charge', 'lostInnerHits', 'pdgId', 'pvAssocQuality', 'trkQuality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_fields = jet_numerical + jet_categorical\n",
    "pf_fields = pf_numerical + pf_categorical\n",
    "\n",
    "jet_keys = [f'jet_{field}' for field in jet_fields]\n",
    "pf_keys = [f'pf_{field}' for field in pf_fields]\n",
    "\n",
    "num_jet = len(jet_keys)\n",
    "num_pf = len(pf_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = glob.glob(os.path.join(parquet_dir, '*'))\n",
    "num_dirs = len(dirs)\n",
    "train_split = int(train_size * num_dirs)\n",
    "test_split = int(test_size * num_dirs) + train_split\n",
    "\n",
    "train_dirs = dirs[:train_split]\n",
    "test_dirs = dirs[train_split:test_split]\n",
    "val_dirs = dirs[test_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/eos/cms/store/group/phys_jetmet/dholmber/jec-dnn/preprocessed/dev/1',\n",
       " '/eos/cms/store/group/phys_jetmet/dholmber/jec-dnn/preprocessed/dev/2',\n",
       " '/eos/cms/store/group/phys_jetmet/dholmber/jec-dnn/preprocessed/dev/3']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet(path):\n",
    "    path = path.decode()\n",
    "\n",
    "    jet = ak.from_parquet(os.path.join(path, 'jet.parquet'))\n",
    "    pf = ak.from_parquet(os.path.join(path, 'pf.parquet'))\n",
    "    \n",
    "    row_lengths = ak.num(pf, axis=1)\n",
    "    flat_pf = ak.flatten(pf, axis=1)\n",
    "    \n",
    "    data = [ak.to_numpy(row_lengths).astype(np.int32), ak.to_numpy(jet.target).astype(np.float32)]\n",
    "    \n",
    "    for field in jet_fields:\n",
    "        data.append(ak.to_numpy(jet[field]).astype(np.float32))\n",
    "\n",
    "    for field in pf_fields:\n",
    "        none_padded_pf = ak.pad_none(pf[field], target=num_points, clip=True, axis=1)\n",
    "        zero_padded_pf = ak.to_numpy(none_padded_pf).filled(0)\n",
    "        data.append(zero_padded_pf.astype(np.float32))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet_wrapper(path):\n",
    "    inp = [path]\n",
    "    Tout = [tf.int32] + [tf.float32] + [tf.float32] * num_jet + [tf.float32] * num_pf\n",
    "    \n",
    "    cols = tf.numpy_function(read_parquet, inp=inp, Tout=Tout)\n",
    "    \n",
    "    keys = ['row_lengths'] + ['target'] + jet_keys + pf_keys\n",
    "    data = {key: value for key, value in zip(keys, cols)}\n",
    "    \n",
    "    data['target'].set_shape((None,))\n",
    "    \n",
    "    row_lengths = data.pop('row_lengths')\n",
    "    row_lengths.set_shape((None,))\n",
    "    \n",
    "    for field in jet_keys:\n",
    "        # Shape from <unknown> to (None,)\n",
    "        data[field].set_shape((None,))\n",
    "        # Shape from (None,) to (None, 1)\n",
    "        data[field] = tf.expand_dims(data[field], axis=1)\n",
    "    \n",
    "    for name in pf_keys:\n",
    "        # Shape from <unknown> to (None, P)\n",
    "        data[name].set_shape((None, num_points))\n",
    "        # Shape from (None, P) to (None, P, 1)\n",
    "        data[name] = tf.expand_dims(data[name], axis=2)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_pf_inputs(data):\n",
    "    data['mask'] = tf.cast(tf.math.not_equal(data['pf_rel_eta'], 0), dtype=tf.float32) # 1 if valid\n",
    "    data['coord_shift'] = tf.multiply(1e6, tf.cast(tf.math.equal(data['mask'], 0), dtype=tf.float32))\n",
    "    data['points'] = tf.concat([data['pf_rel_eta'], data['pf_rel_phi']], axis=2)\n",
    "    \n",
    "    jet_data = tf.concat([data[key] for key in jet_keys], axis=1)\n",
    "    pf_data = tf.concat([data[key] for key in pf_keys], axis=2)\n",
    "    \n",
    "    inputs = (pf_data, jet_data, data['points'], data['coord_shift'], data['mask'])\n",
    "    return inputs, data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(paths):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(paths)\n",
    "    ds = ds.map(read_parquet_wrapper, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.map(prepare_pf_inputs, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.unbatch().batch(batch_size)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-21 11:27:09.104941: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-21 11:27:09.112292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-21 11:27:09.113486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:07.0 name: Tesla V100S-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.597GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 1.03TiB/s\n",
      "2021-07-21 11:27:09.113636: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/nvidia-driver/lib64\n",
      "2021-07-21 11:27:09.113722: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/nvidia-driver/lib64\n",
      "2021-07-21 11:27:09.113862: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/nvidia-driver/lib64\n",
      "2021-07-21 11:27:09.113941: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/nvidia-driver/lib64\n",
      "2021-07-21 11:27:09.114018: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/nvidia-driver/lib64\n",
      "2021-07-21 11:27:09.114093: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/nvidia-driver/lib64\n",
      "2021-07-21 11:27:09.114166: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/nvidia-driver/lib64\n",
      "2021-07-21 11:27:09.114242: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/nvidia-driver/lib64\n",
      "2021-07-21 11:27:09.114264: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-07-21 11:27:09.115476: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-21 11:27:09.115881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-21 11:27:09.115907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
     ]
    }
   ],
   "source": [
    "train_ds = create_dataset(train_dirs).shuffle(64)\n",
    "val_ds = create_dataset(val_dirs)\n",
    "test_ds = create_dataset(test_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Activation, Add, BatchNormalization, Conv2D, Dense, Dropout, Layer, Multiply, Concatenate\n",
    "from src.layers import Mean, Max, Expand, Squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_particle_net():\n",
    "    \"\"\"\n",
    "    ParticleNet: Jet Tagging via Particle Clouds\n",
    "    arxiv.org/abs/1902.08570\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shapes : dict\n",
    "        The shapes of each input (`points`, `features`, `mask`).\n",
    "    \"\"\"\n",
    "\n",
    "    features = Input(name='features', shape=(num_points, num_pf))\n",
    "    globals = Input(name='globals', shape=(num_jet,))\n",
    "    points = Input(name='points', shape=(num_points, 2))\n",
    "    coord_shift = Input(name='coord_shift', shape=(num_points, 1))\n",
    "    mask = Input(name='mask', shape=(num_points, 1))\n",
    "\n",
    "    outputs = particle_net_base(points, features, mask, coord_shift, globals)\n",
    "\n",
    "    model = Model(inputs=[features, globals, points, coord_shift, mask], outputs=outputs)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def particle_net_base(points, features, mask, coord_shift, globals):\n",
    "    \"\"\"\n",
    "    points : (N, P, C_coord)\n",
    "    features:  (N, P, C_features), optional\n",
    "    mask: (N, P, 1), optional\n",
    "    \"\"\"\n",
    "\n",
    "    # fts = tf.squeeze(BatchNormalization(name='fts_bn')(tf.expand_dims(features, axis=2)), axis=2)\n",
    "    fts = features\n",
    "    for layer_idx, sub_channels in enumerate(channels, start=1):\n",
    "        pts = Add(name=f'add_{layer_idx}')([coord_shift, points]) if layer_idx == 1 else Add(name=f'add_{layer_idx}')([coord_shift, fts])\n",
    "        fts = edge_conv(\n",
    "            pts, fts, num_points, sub_channels, name=f'edge_conv_{layer_idx}'\n",
    "        )\n",
    "\n",
    "    fts = Multiply()([fts, mask])\n",
    "\n",
    "    pool = Mean(axis=1)(fts) # (N, C)\n",
    "\n",
    "    x = Concatenate(name='head')([pool, globals])\n",
    "\n",
    "    for layer_idx, n in enumerate(units):\n",
    "        x = Dense(n)(x)\n",
    "        x = Activation(activation)(x)\n",
    "        if dropout:\n",
    "            x = Dropout(dropout)(x)\n",
    "    out = Dense(1, name='out')(x)\n",
    "    return out # (N, num_classes)\n",
    "\n",
    "\n",
    "def edge_conv(points, features, num_points, sub_channels, name):\n",
    "    \"\"\"EdgeConv\n",
    "    Args:\n",
    "        K: int, number of neighbors\n",
    "        in_channels: # of input channels\n",
    "        channels: tuple of output channels\n",
    "        pooling: pooling method ('max' or 'average')\n",
    "    Inputs:\n",
    "        points: (N, P, C_p)\n",
    "        features: (N, P, C_0)\n",
    "    Returns:\n",
    "        transformed points: (N, P, C_out), C_out = channels[-1]\n",
    "    \"\"\"\n",
    "\n",
    "    fts = features\n",
    "    knn_fts = KNearestNeighbors(num_points, K, name=f'{name}_knn')([points, fts])\n",
    "\n",
    "    x = knn_fts\n",
    "    for idx, channel in enumerate(sub_channels, start=1):\n",
    "        x = Conv2D(\n",
    "            channel, kernel_size=(1, 1), strides=1, data_format='channels_last',\n",
    "            use_bias=False if batch_norm else True, kernel_initializer=initializer, name=f'{name}_conv_{idx}'\n",
    "        )(x)\n",
    "        if batch_norm:\n",
    "            x = BatchNormalization(name=f'{name}_batchnorm_{idx}')(x)\n",
    "        if activation:\n",
    "            x = Activation(activation, name=f'{name}_activation_{idx}')(x)\n",
    "\n",
    "    if pooling == 'max':\n",
    "        fts = Max(axis=2, name=f'{name}_max')(x) # (N, P, C')\n",
    "    else:\n",
    "        fts = Mean(axis=2, name=f'{name}_mean')(x) # (N, P, C')\n",
    "\n",
    "    if shortcut:\n",
    "        sc = Expand(axis=2, name=f'{name}_shortcut_expand')(features)\n",
    "        sc = Conv2D(\n",
    "            sub_channels[-1], kernel_size=(1, 1), strides=1, data_format='channels_last',\n",
    "            use_bias=False if batch_norm else True, kernel_initializer=initializer, name=f'{name}_shortcut_conv'\n",
    "        )(sc)\n",
    "        if batch_norm:\n",
    "            sc = BatchNormalization(name=f'{name}_shortcut_batchnorm')(sc)\n",
    "        sc = Squeeze(axis=2, name=f'{name}_shortcut_squeeze')(sc)\n",
    "\n",
    "        x = Add(name=f'{name}_add')([sc, fts])\n",
    "    else:\n",
    "        x = fts\n",
    "\n",
    "    return Activation(activation, name=f'{name}_activation')(x) # (N, P, C')\n",
    "\n",
    "\n",
    "class KNearestNeighbors(Layer):\n",
    "    def __init__(self, num_points, k, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_points = num_points\n",
    "        self.k = k\n",
    "\n",
    "    def call(self, inputs):\n",
    "        points, features = inputs\n",
    "        # distance\n",
    "        D = batch_distance_matrix_general(points, points) # (N, P, P)\n",
    "        _, top_k_indices = tf.math.top_k(-D, k=self.k + 1) # (N, P, K+1)\n",
    "        top_k_indices = top_k_indices[:, :, 1:] # (N, P, K)\n",
    "\n",
    "        queries_shape = tf.shape(features)\n",
    "        batch_size = queries_shape[0]\n",
    "        batch_indices = tf.tile(tf.reshape(tf.range(batch_size), (-1, 1, 1, 1)), (1, self.num_points, self.k, 1))\n",
    "        indices = tf.concat([batch_indices, tf.expand_dims(top_k_indices, axis=3)], axis=3) # (N, P, K, 2)\n",
    "        \n",
    "        knn_fts =  tf.gather_nd(features, indices) # (N, P, K, C)\n",
    "        knn_fts_center = tf.tile(tf.expand_dims(features, axis=2), (1, 1, self.k, 1)) # (N, P, K, C)\n",
    "\n",
    "        return tf.concat([knn_fts_center, tf.subtract(knn_fts, knn_fts_center)], axis=-1) # (N, P, K, 2*C)\n",
    "\n",
    "\n",
    "# A shape is (N, P_A, C), B shape is (N, P_B, C)\n",
    "# D shape is (N, P_A, P_B)\n",
    "def batch_distance_matrix_general(A, B):\n",
    "    r_A = tf.math.reduce_sum(A * A, axis=2, keepdims=True)\n",
    "    r_B = tf.math.reduce_sum(B * B, axis=2, keepdims=True)\n",
    "    m = tf.linalg.matmul(A, tf.transpose(B, perm=(0, 2, 1)))\n",
    "    D = r_A - 2 * m + tf.transpose(r_B, perm=(0, 2, 1))\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "coord_shift (InputLayer)        [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "points (InputLayer)             [(None, 100, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 100, 2)       0           coord_shift[0][0]                \n",
      "                                                                 points[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           [(None, 100, 16)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_knn (KNearestNeighb (None, 100, 16, 32)  0           add_1[0][0]                      \n",
      "                                                                 features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_conv_1 (Conv2D)     (None, 100, 16, 64)  2112        edge_conv_1_knn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_activation_1 (Activ (None, 100, 16, 64)  0           edge_conv_1_conv_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_conv_2 (Conv2D)     (None, 100, 16, 64)  4160        edge_conv_1_activation_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_activation_2 (Activ (None, 100, 16, 64)  0           edge_conv_1_conv_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_conv_3 (Conv2D)     (None, 100, 16, 64)  4160        edge_conv_1_activation_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_activation_3 (Activ (None, 100, 16, 64)  0           edge_conv_1_conv_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_mean (Mean)         (None, 100, 64)      0           edge_conv_1_activation_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_1_activation (Activat (None, 100, 64)      0           edge_conv_1_mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 100, 64)      0           coord_shift[0][0]                \n",
      "                                                                 edge_conv_1_activation[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_knn (KNearestNeighb (None, 100, 16, 128) 0           add_2[0][0]                      \n",
      "                                                                 edge_conv_1_activation[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_conv_1 (Conv2D)     (None, 100, 16, 128) 16512       edge_conv_2_knn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_activation_1 (Activ (None, 100, 16, 128) 0           edge_conv_2_conv_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_conv_2 (Conv2D)     (None, 100, 16, 128) 16512       edge_conv_2_activation_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_activation_2 (Activ (None, 100, 16, 128) 0           edge_conv_2_conv_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_conv_3 (Conv2D)     (None, 100, 16, 128) 16512       edge_conv_2_activation_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_activation_3 (Activ (None, 100, 16, 128) 0           edge_conv_2_conv_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_mean (Mean)         (None, 100, 128)     0           edge_conv_2_activation_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_2_activation (Activat (None, 100, 128)     0           edge_conv_2_mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 100, 128)     0           coord_shift[0][0]                \n",
      "                                                                 edge_conv_2_activation[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_knn (KNearestNeighb (None, 100, 16, 256) 0           add_3[0][0]                      \n",
      "                                                                 edge_conv_2_activation[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_conv_1 (Conv2D)     (None, 100, 16, 256) 65792       edge_conv_3_knn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_activation_1 (Activ (None, 100, 16, 256) 0           edge_conv_3_conv_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_conv_2 (Conv2D)     (None, 100, 16, 256) 65792       edge_conv_3_activation_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_activation_2 (Activ (None, 100, 16, 256) 0           edge_conv_3_conv_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_conv_3 (Conv2D)     (None, 100, 16, 256) 65792       edge_conv_3_activation_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_activation_3 (Activ (None, 100, 16, 256) 0           edge_conv_3_conv_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_mean (Mean)         (None, 100, 256)     0           edge_conv_3_activation_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "edge_conv_3_activation (Activat (None, 100, 256)     0           edge_conv_3_mean[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "mask (InputLayer)               [(None, 100, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 100, 256)     0           edge_conv_3_activation[0][0]     \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "mean_1 (Mean)                   (None, 256)          0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "globals (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "head (Concatenate)              (None, 266)          0           mean_1[0][0]                     \n",
      "                                                                 globals[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          34176       head[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          16512       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "out (Dense)                     (None, 1)            129         activation_3[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 308,161\n",
      "Trainable params: 308,161\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=0.001>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn = get_particle_net()\n",
    "dnn.compile(optimizer=optimizer, loss=loss)\n",
    "dnn.optimizer.lr.assign(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(dnn, dpi=100, show_shapes=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 20s 10s/step - loss: 11.6469 - val_loss: 10.6499\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 17s 10s/step - loss: 8.7719 - val_loss: 4.3419\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 18s 10s/step - loss: 2.8284 - val_loss: 4.7672\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 18s 10s/step - loss: 5.3100 - val_loss: 0.4959\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 18s 10s/step - loss: 2.2898 - val_loss: 3.0230\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 18s 10s/step - loss: 2.5303 - val_loss: 1.5037\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 18s 10s/step - loss: 2.0474 - val_loss: 1.1952\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 17s 9s/step - loss: 0.7986 - val_loss: 0.7362\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 17s 9s/step - loss: 0.6192 - val_loss: 0.4734\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 17s 9s/step - loss: 0.7848 - val_loss: 0.5175\n"
     ]
    }
   ],
   "source": [
    "fit = dnn.fit(train_ds, validation_data=val_ds, epochs=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "gitlab-registry.cern.ch/dholmber/jec-dnn:latest",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": false,
   "steps_defaults": [],
   "volume_access_mode": "rwm",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
