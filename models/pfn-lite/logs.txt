GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]
Model: "dnn"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
charged_constituents (InputLaye [(None, None, 25)]   0                                            
__________________________________________________________________________________________________
neutral_constituents (InputLaye [(None, None, 11)]   0                                            
__________________________________________________________________________________________________
secondary_vertices (InputLayer) [(None, None, 10)]   0                                            
__________________________________________________________________________________________________
ch_time_distributed (TimeDistri (None, None, 64)     3408        charged_constituents[0][0]       
__________________________________________________________________________________________________
ne_time_distributed (TimeDistri (None, None, 64)     3184        neutral_constituents[0][0]       
__________________________________________________________________________________________________
sv_time_distributed (TimeDistri (None, None, 32)     944         secondary_vertices[0][0]         
__________________________________________________________________________________________________
ch_head (Sum)                   (None, 64)           0           ch_time_distributed[0][0]        
__________________________________________________________________________________________________
ne_head (Sum)                   (None, 64)           0           ne_time_distributed[0][0]        
__________________________________________________________________________________________________
sv_head (Sum)                   (None, 32)           0           sv_time_distributed[0][0]        
__________________________________________________________________________________________________
globals (InputLayer)            [(None, 11)]         0                                            
__________________________________________________________________________________________________
head (Concatenate)              (None, 171)          0           ch_head[0][0]                    
                                                                 ne_head[0][0]                    
                                                                 sv_head[0][0]                    
                                                                 globals[0][0]                    
__________________________________________________________________________________________________
head_dense_1 (Dense)            (None, 128)          21888       head[0][0]                       
__________________________________________________________________________________________________
head_batch_normalization_1 (Bat (None, 128)          512         head_dense_1[0][0]               
__________________________________________________________________________________________________
head_activation_1 (Activation)  (None, 128)          0           head_batch_normalization_1[0][0] 
__________________________________________________________________________________________________
head_dense_2 (Dense)            (None, 64)           8192        head_activation_1[0][0]          
__________________________________________________________________________________________________
head_batch_normalization_2 (Bat (None, 64)           256         head_dense_2[0][0]               
__________________________________________________________________________________________________
head_activation_2 (Activation)  (None, 64)           0           head_batch_normalization_2[0][0] 
__________________________________________________________________________________________________
head_dense_3 (Dense)            (None, 32)           2048        head_activation_2[0][0]          
__________________________________________________________________________________________________
head_batch_normalization_3 (Bat (None, 32)           128         head_dense_3[0][0]               
__________________________________________________________________________________________________
head_activation_3 (Activation)  (None, 32)           0           head_batch_normalization_3[0][0] 
__________________________________________________________________________________________________
head_dense_4 (Dense)            (None, 16)           512         head_activation_3[0][0]          
__________________________________________________________________________________________________
head_batch_normalization_4 (Bat (None, 16)           64          head_dense_4[0][0]               
__________________________________________________________________________________________________
head_activation_4 (Activation)  (None, 16)           0           head_batch_normalization_4[0][0] 
__________________________________________________________________________________________________
head_dense_5 (Dense)            (None, 8)            128         head_activation_4[0][0]          
__________________________________________________________________________________________________
head_batch_normalization_5 (Bat (None, 8)            32          head_dense_5[0][0]               
__________________________________________________________________________________________________
head_activation_5 (Activation)  (None, 8)            0           head_batch_normalization_5[0][0] 
__________________________________________________________________________________________________
output (Dense)                  (None, 1)            9           head_activation_5[0][0]          
==================================================================================================
Total params: 41,305
Trainable params: 40,249
Non-trainable params: 1,056
__________________________________________________________________________________________________
Model: "ch_model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
ch_slice (InputLayer)        [(None, 25)]              0         
_________________________________________________________________
ch_dense_1 (Dense)           (None, 16)                400       
_________________________________________________________________
ch_batch_normalization_1 (Ba (None, 16)                64        
_________________________________________________________________
ch_activation_1 (Activation) (None, 16)                0         
_________________________________________________________________
ch_dense_2 (Dense)           (None, 32)                512       
_________________________________________________________________
ch_batch_normalization_2 (Ba (None, 32)                128       
_________________________________________________________________
ch_activation_2 (Activation) (None, 32)                0         
_________________________________________________________________
ch_dense_3 (Dense)           (None, 64)                2048      
_________________________________________________________________
ch_batch_normalization_3 (Ba (None, 64)                256       
_________________________________________________________________
ch_activation_3 (Activation) (None, 64)                0         
=================================================================
Total params: 3,408
Trainable params: 3,184
Non-trainable params: 224
_________________________________________________________________
Model: "ne_model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
ne_slice (InputLayer)        [(None, 11)]              0         
_________________________________________________________________
ne_dense_1 (Dense)           (None, 16)                176       
_________________________________________________________________
ne_batch_normalization_1 (Ba (None, 16)                64        
_________________________________________________________________
ne_activation_1 (Activation) (None, 16)                0         
_________________________________________________________________
ne_dense_2 (Dense)           (None, 32)                512       
_________________________________________________________________
ne_batch_normalization_2 (Ba (None, 32)                128       
_________________________________________________________________
ne_activation_2 (Activation) (None, 32)                0         
_________________________________________________________________
ne_dense_3 (Dense)           (None, 64)                2048      
_________________________________________________________________
ne_batch_normalization_3 (Ba (None, 64)                256       
_________________________________________________________________
ne_activation_3 (Activation) (None, 64)                0         
=================================================================
Total params: 3,184
Trainable params: 2,960
Non-trainable params: 224
_________________________________________________________________
Model: "sv_model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
sv_slice (InputLayer)        [(None, 10)]              0         
_________________________________________________________________
sv_dense_1 (Dense)           (None, 8)                 80        
_________________________________________________________________
sv_batch_normalization_1 (Ba (None, 8)                 32        
_________________________________________________________________
sv_activation_1 (Activation) (None, 8)                 0         
_________________________________________________________________
sv_dense_2 (Dense)           (None, 16)                128       
_________________________________________________________________
sv_batch_normalization_2 (Ba (None, 16)                64        
_________________________________________________________________
sv_activation_2 (Activation) (None, 16)                0         
_________________________________________________________________
sv_dense_3 (Dense)           (None, 32)                512       
_________________________________________________________________
sv_batch_normalization_3 (Ba (None, 32)                128       
_________________________________________________________________
sv_activation_3 (Activation) (None, 32)                0         
=================================================================
Total params: 944
Trainable params: 832
Non-trainable params: 112
_________________________________________________________________
Epoch 1/100
8075/8075 [==============================] - 428s 50ms/step - loss: 0.0892 - val_loss: 0.0834
Epoch 2/100
8075/8075 [==============================] - 419s 50ms/step - loss: 0.0830 - val_loss: 0.0822
Epoch 3/100
8075/8075 [==============================] - 420s 50ms/step - loss: 0.0822 - val_loss: 0.0822
Epoch 4/100
8075/8075 [==============================] - 419s 50ms/step - loss: 0.0818 - val_loss: 0.0815
Epoch 5/100
8075/8075 [==============================] - 419s 50ms/step - loss: 0.0815 - val_loss: 0.0820
Epoch 6/100
8075/8075 [==============================] - 421s 50ms/step - loss: 0.0813 - val_loss: 0.0813
Epoch 7/100
8075/8075 [==============================] - 421s 50ms/step - loss: 0.0811 - val_loss: 0.0810
Epoch 8/100
8075/8075 [==============================] - 419s 51ms/step - loss: 0.0809 - val_loss: 0.0809
Epoch 9/100
8075/8075 [==============================] - 421s 50ms/step - loss: 0.0808 - val_loss: 0.0809
Epoch 10/100
8075/8075 [==============================] - 419s 51ms/step - loss: 0.0807 - val_loss: 0.0808
Epoch 11/100
8075/8075 [==============================] - 418s 49ms/step - loss: 0.0805 - val_loss: 0.0809
Epoch 12/100
8075/8075 [==============================] - 419s 50ms/step - loss: 0.0805 - val_loss: 0.0805
Epoch 13/100
8075/8075 [==============================] - 420s 50ms/step - loss: 0.0804 - val_loss: 0.0807
Epoch 14/100
8075/8075 [==============================] - 421s 50ms/step - loss: 0.0803 - val_loss: 0.0804
Epoch 15/100
8075/8075 [==============================] - 419s 50ms/step - loss: 0.0802 - val_loss: 0.0822
Epoch 16/100
8075/8075 [==============================] - 423s 51ms/step - loss: 0.0802 - val_loss: 0.0803
Epoch 17/100
8075/8075 [==============================] - 420s 51ms/step - loss: 0.0801 - val_loss: 0.0802
Epoch 18/100
8075/8075 [==============================] - 421s 51ms/step - loss: 0.0801 - val_loss: 0.0800
Epoch 19/100
8075/8075 [==============================] - 421s 51ms/step - loss: 0.0800 - val_loss: 0.0805
Epoch 20/100
8075/8075 [==============================] - 421s 50ms/step - loss: 0.0800 - val_loss: 0.0800
Epoch 21/100
8075/8075 [==============================] - 420s 50ms/step - loss: 0.0799 - val_loss: 0.0801
Epoch 22/100
8075/8075 [==============================] - 420s 50ms/step - loss: 0.0799 - val_loss: 0.0800
Epoch 23/100
8075/8075 [==============================] - 419s 50ms/step - loss: 0.0799 - val_loss: 0.0803

Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.
Epoch 24/100
8075/8075 [==============================] - 421s 50ms/step - loss: 0.0796 - val_loss: 0.0795
Epoch 25/100
8075/8075 [==============================] - 420s 51ms/step - loss: 0.0795 - val_loss: 0.0796
Epoch 26/100
8075/8075 [==============================] - 421s 50ms/step - loss: 0.0794 - val_loss: 0.0795
Epoch 27/100
8075/8075 [==============================] - 419s 50ms/step - loss: 0.0794 - val_loss: 0.0795
Epoch 28/100
8075/8075 [==============================] - 419s 50ms/step - loss: 0.0794 - val_loss: 0.0795
Epoch 29/100
8075/8075 [==============================] - 419s 50ms/step - loss: 0.0794 - val_loss: 0.0795

Epoch 00029: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.
Epoch 30/100
8075/8075 [==============================] - 419s 50ms/step - loss: 0.0793 - val_loss: 0.0794
Epoch 31/100
8075/8075 [==============================] - 422s 50ms/step - loss: 0.0793 - val_loss: 0.0794
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
2637/2637 [==============================] - 91s 28ms/step - loss: 0.0796
Test loss: 0.07955656200647354
Inference time: 92.85515427589417
